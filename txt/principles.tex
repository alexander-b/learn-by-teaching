As part of the research, reviews of related services offering learning
experiences were written. The individual findings can be found in Section
~\ref{ch:related} on related work (found on page~\pageref{ch:related}). In this
Section, we try to apply the findings towards our end of producing a system fit
for students and educators alike.

We wish to discuss \textit{learning} at first. A common technique used in most
of these systems seems to be \textbf{spacing} combined with \textbf{testing},
that is the pacing of repetition throughout time. This approach is well-proven
by research, and could be implemented both as a part of our services (allowing
module authors to apply it to their own students), or as a part of the
experience of learning the tools. An example might be: `After 5 days, please
repeat this factoid and test the student.` Of course, such an approach might
prove cumbersome, and techniques like machine learning might automate it in some
meaningful fashion using a data-oriented approached.

In testing, there exists mainly three techniques for assessment:

\begin{itemize}
\item Reading, which is the reproduction of textual representations of the fact.
\item Multiple choice, where one is allowed multiple alternatives, where at
least one of them should be true. Often one or more of the alternatives are `the
odd man out`, to test the student's ability to discriminate irrelevant concepts.
\item Generation, where the user is made to produce something, for example
filling in a word. As noted by \cite{potts2014benefit} and others, this
technique is highly efficient with regards to retention, especially when
combined with quick feedback.
\end{itemize}

Thus, we consider generation. An example of this might be generating a formally
valid blueprint of some e-module, and asking the user what it does. Or it might
be to make the user connect the relevant parts to make it work as desired. Thus,
we foster true comprehension of the system mechanics and avoid cramming. As
noted in the literature in the Memrise review, errorful generation (that is
getting it wrong) might actually be benefitial, and something we should not
punish the user for doing. Rather, we suggest to embrace it and make failure as
smooth as possible, with quick iterations.

A huge part of any learning system is the \textit{metaphor}, or the user
interface. The system needs to provide some incentive for the user to perform
some action. Thus, the user interface will always be a question of demographics.
We suggest that the user interface should be amenable to at least some
simplifications to scale down to the technology-native elementary school
demographic. Some concrete suggestions are:

\begin{itemize}
\item The user interface needs to take into consideration the rather poor motor
skills of young children.\cite{kidsquora} Thus, tap actions should not be that
precise or responsive, but instead allow for some slack. For example, multiple
taps should not result in multiple windows, but rather provide a time buffer for
the action to launch. Also, the hit box of buttons should be greater than their
actual size.
\item Avoid splash screens,\cite{kidsluke} and in general get to the point as quickly as
possible. Thus, it might be better to provide a simpler, but usable interface
rather than a complete experience first-hand. For example, one might wish to
avoid modal dialogues, as they provide children which textual choice, which they
might not understand or be interested in.
\item To provide some sense of continuity, and also a way of accumulating
rewards, the user might construct an avatar. This concept is known from video
games, and has already been suggested to be a viable way of familiarising
children with complicated services like search engines.
In \cite{gossen2012search}, an avatar helps the child search the web, and the
results are put into a `treasure chest.`
\end{itemize}

Unfortunately, we were not able to locate high-quality sources of research in
this area. Most sources are based on de-facto and ad-hoc solutions, with little
or no scientific basis outside of in-house usability studies. Thus, we are
potentially missing out on a great deal of useful data.

\textbf{Takeaway points}, based on previous discussion and the reviews:

\begin{itemize}
\item Spaced learning with testing using generation fosters comprehension and
recall. We need to embrace generating errors as a way of learning.
\item Quick and simple feedback with additive gains facilitate user engagement
and learning greatly, and promotes attention continuity.
\item The system should provide a simple (preferably physical) metaphor as part
of its user story.
\item The system needs to use open, free standards to enhance composition and
foster a culture of reuse and experimentation.
\item We should strive for feature parity between different clients, to simplify
the user story and provide a consistent experience.
\item A strong, data-driven approach involving the users strengthens community
relations and improved quality by providing relevant feedback to create,
enhance, or QA existing material.
\end{itemize}
